
% Distributed under the MIT License.
% (See accompanying file LICENSE.txt)
% (C) Copyright NoWork team

\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{dirtree}

\lstset{language=Caml}

\title{NoWork\\
Developer manual}
\author{NoWork development team\\[2em]}
\date\today

\begin{document}
\maketitle

\section{Introduction}

This document presents to developers NoWork, a nominal rewriting workbench. Anyone interested by the mechanisms of NoWork or rewriting system in general might find interests in this document. It is also essential if you want to modify this project. We expect that you first read the user manual and played a bit with the interpreter. If you intend to modify this project and provide a pull-request, you can read the coding style document.
\newline

The section \ref{install} prepares you to hack on NoWork by installing everything needed, we next give an overview of the global architecture in section \ref{architecture}. The modules presented are further described in the following sections, the top-level is presented in section \ref{top-level}. The data structures encoding the language are presented in section \ref{data-system} and we highlight the different representation occurring during the system processing. The section \ref{data-term} shows different term structure and more particularly, explains how the hash-consing is working and why it is important in this project. The typing phase is described in section \ref{typechecking} and is followed by the algorithms section. The algorithm selecting a rule via its pattern is presented in the section \ref{pattern-matching}, the matching rules are then applied to a term with a specific strategy, the section \ref{rewriting} is dedicated to the rewriting algorithm. This document concludes with a rational in section \ref{rational} discussing the different high-level choices and why we make these choices.

\section{Installing and hack on NoWork}
\label{install}
%% Matthieu
How to install and begin to develop with NoWork.

\section{Architecture}
\label{architecture}
%% Mathieu

Here comes a simplified description of the directory layout :
\bigskip

\dirtree{%
.1 /.
.2 doc.
.2 data.
.3 error.
.3 test.
.4 run-pass.
.4 run-fail.
.2 src.
.3 algorithms.
.3 auto\_gen.
.3 generator.
.3 interactive.
.3 parser.
.3 system.
}
\bigskip

And now a more precise description of these directories :

\begin{itemize}

\item \emph{doc} : obviously contains documentation files (user manual, developper manual, coding style, ...)
\item \emph{data/error} : custom exceptions declaration in \emph{*.conf} files (need to be declared here to be used in tests)
\item \emph{data/test} : functional tests framework, test files are added in either \emph{run-fail} or \emph{run-pass}, and test expectations in \emph{test.nw}
\item \emph{src/algorithms} : general algorithms that don't rely on one particular system such as matching and rewriting
\item \emph{src/generator} : generated errors system
\item \emph{src/interactive} : top-level system
\item \emph{src/system} : contains the different AST representations, type checking modules (\emph{type\_checking} and \emph{term\_checker}), and symbol tables

\end{itemize}

\section{Top-level}
\label{top-level}
%% Vincent
Present the top-level and coding specificities.

\section{Parsing and data representation}
\label{data}

\subsection{System representation}
\label{data-system}
%% RÃ©my
Which transformation of the representation of the system occurred and why?

\subsection{Term representation}
\label{data-term}
%% Pierrick Matthieu
During the process between the parsing and the rewriting of a term, the
structure reprensenting the term is transformed step by step.

\subsubsection{From parsing to semantic-checking}
Parsed terms are transformed in the following \verb?term_ast? :
\begin{lstlisting}
  type info = Lexing.position

  type ident = string

  type term_desc =
  | Const
  | Term of term_ast list
  | Var

  and term_ast =
  {
    name : string;
    info : info;
    desc : term_desc;
  }
\end{lstlisting}

This AST is used only to keep position (in the original file) and structure
informations.
But it is made using only grammatical informations, so it can be
semantically incoherent. That is why it will be transformed during the
type-checking.

\subsubsection{From semantic-checking to type-checking}
The second transformation take a \verb?term_ast? and use semantic informations
contained in the rewriting system to check the semantic of the AST (term
arity and well definition of each symbol)  then
construct an AST with that additional informations (differentiation between
bounded atoms and atom's binders). Now, the term is ready to be type-checked.
\\
N.B. : This AST is called \verb?term_ast_with_binders? (because of his
author's lack of inspiration) in the \verb?term_ast_typed.ml?.
It constructed by \verb?construc_ast_checked? in \verb?term_checker.ml?

\subsubsection{From type-checking to hash-consing}
At the end, the type-checking, processed on the precedent AST, gives a
typed AST keeping only structure and type informations of the original AST.
It is made by \verb?check_type_of_term?.
\\
A term passing all of the steps is considered as wel formed and typed, then
the user can manipulate and particulary rewrite it. In order to have an
efficient rewriting the AST must be transformed a last time.

\subsubsection{Hash-consing}
\label{data-term-hash-consing}
%% Pierrick
\input{dev_hashconsing.tex}

\section{Type-checking}
\label{typechecking}
%% Ma(t.)hieu

\section{Algorithms}
\label{algorithms}

\subsection{Pattern-matching}
\label{pattern-matching}

The pattern matching algorithm returns a set of couple of placeholders and sub-terms regarding a pattern and a term. It is implemented in the files \texttt{src/algorithms/matching.\{ml,mli\}} and is well-commented. Consider the following extract of the Peano rewriting system:
\begin{lstlisting}
rule [add-l] :
  Add(Successor(?u), ?v) => Successor(Add(?u, ?v))

rule [add-r] :
  Add(?u, Successor(?v)) => Successor(Add(?u, ?v))

rule [div-same] :
  Div(?u, ?u) => Successor(Zero)
\end{lstlisting}

We simulate the pattern matching algorithm with the pattern of the rule \texttt{add-l} and the term \texttt{Add(Successor(Zero), Zero)} in figure \ref{peano-example}.

\begin{figure}
  \centering
  \includegraphics[scale=0.6, angle=270]{example-peano.pdf}
  \caption{Pattern matching on Peano term}
  \label{peano-example}
\end{figure}

The algorithm returns a type \texttt{map option}, if the term doesn't match the pattern, it returns \texttt{None}, otherwise it returns the bindings between the placeholders and sub-terms.
\newline

The algorithm is rather simple as it just travels at the same time the AST of the pattern and term. A problem appears in presence of non-linear pattern such as in the rule \texttt{div-same} because there are two identical placeholders. Comparing two terms modulo alpha-conversion have a bad complexity (it depends on the term length and on the number of binders). For this purpose, we firstly hash-consed our term as explained in section \ref{data-term-hash-consing} and we use it whenever we have to compare two sub-terms sharing a same placeholder. This have a constant complexity. We still need to go through the initial term since the hash-consed representation erased any notion of name and is useless to compare constant name and operators with patterns.

\subsection{Rewriting}
\label{rewriting}
%% Roven

\section{Rational}
\label{rational}
%% Everybody
Important decision that we made such as : Why have we split the language in an interactive and "normal" mode? Why do we have only one parser/lexer (instead of one for system and one for term).


\end{document}
